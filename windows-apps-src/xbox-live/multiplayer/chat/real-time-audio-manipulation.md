---
title: Real-time audio manipulation
author: KevinAsgari
description: Learn how to manipulate and process the chat audio captured by Game Chat 2.
ms.author: kevinasg
ms.date: 05/10/2018
ms.topic: article
ms.prod: windows
ms.technology: uwp
keywords: xbox live, xbox, games, uwp, windows 10, xbox one, game chat 2, game chat, voice communication, buffer manipulation, audio manipulation
ms.localizationpriority: low
---

# Real-time audio manipulation

Game Chat 2 gives developers the option to insert themselves into the chat audio pipeline to inspect and manipulate the players' chat audio data. This can be useful for applying interesting audio effects to players' voices in game. Game Chat 2's audio manipulation pipeline is interacted with through audio stream objects that can be polled for audio data. As opposed to using callbacks, this model allows developers to inspect or manipulate audio on whatever processing thread is most convenient for them.

A brief walkthrough using real-time audio manipulation is featured below, containing the following topics:

1. [Initializing the audio manipulation pipeline](#initializing-the-audio-manipulation-pipeline)
2. [Processing audio stream state changes](#processing-audio-stream-state-changes)
3. [Manipulating pre-encode chat audio](#manipulating-pre-encode-chat-audio-data)
4. [Manipulating post-decode chat audio](#manipulating-post-decode-chat-audio-data)
5. [Chat user lifetimes](#chat-user-lifetimes)

## Initializing the audio manipulation pipeline

Game Chat 2 by default will not enable real-time audio manipulation. To enable real-time audio manipulation, the app must specify which form(s) of audio manipulation it would like enabled in `chat_manager::initialize()` by setting the audioManipulationMode parameter.

Currently, the following audio manipulation forms are supported:

* `game_chat_audio_manipulation_mode_flags::none` - Disables audio manipulation. This is the default configuration. In this mode, chat audio will flow uninterrupted.
* `game_chat_audio_manipulation_mode_flags::pre_encode_stream_manipulation` - Enables pre-encode audio manipulation. In this mode, all chat audio generated by local users will be fed through the audio manipulation pipeline before it is encoded. Even if the app is only inspecting the chat audio data and not manipulating it, it is still the  app's responsibility to submit the unaltered audio buffers back to Game Chat 2 so that they can be encoded and transmitted.
* `game_chat_audio_manipulation_mode_flags::post_decode_stream_manipulation` - Enables post-decode audio manipulation. This mode is currently in development and should not be used.

## Processing audio stream state changes

Game Chat 2 provides updates to the state of audio streams through `game_chat_stream_state_change` structures. These updates store information about which stream has been updated and how it has been updated. These updates can be polled for through calls to the `chat_manager::start_processing_stream_state_changes()` and `chat_manager::finish_processing_stream_state_changes()` pair of methods. This pair of methods provides all of the latest, queued audio stream state updates as an array of `game_chat_stream_state_change` structure pointers. Apps should iterate over the array and handle each update appropriately. Once all available `game_chat_stream_state_change` updates have been handled, that array should be passed back to Game Chat 2 through `chat_manager::finish_processing_stream_state_changes()`. For example:

```cpp
uint32_t streamStateChangeCount;
game_chat_stream_state_change_array streamStateChanges;
chat_manager::singleton_instance().start_processing_stream_state_changes(&streamStateChangeCount, &streamStateChanges);

for (uint32_t streamStateChangeIndex = 0; streamStateChangeIndex < streamStateChangeCount; ++streamStateChangeIndex)
{
    switch (streamStateChanges[streamStateChangeIndex]->state_change_type)
    {
        case game_chat_stream_state_change_type::pre_encode_audio_stream_created:
        {
            HandlePreEncodeAudioStreamCreated(streamStateChanges[streamStateChangeIndex].pre_encode_audio_stream);
            break;
        }

        case Xs::game_chat_2::game_chat_stream_state_change_type::pre_encode_audio_stream_closed:
        {
            HandlePreEncodeAudioStreamClosed(streamStateChanges[streamStateChangeIndex].pre_encode_audio_stream);
            break;
        }

        ...
    }
}
chat_manager::singleton_instance().finish_processing_stream_state_changes(streamStateChanges);
```

## Manipulating pre-encode chat audio data

Game Chat 2 provides access to pre-encode chat audio data for local users through the `pre_encode_audio_stream` class.

### Stream Lifetime
When a new `pre_encode_audio_stream` instance is ready for the app to use, it will be delivered through a `game_chat_stream_state_change` structure with it's `state_change_type` field set to `game_chat_stream_state_change_type::pre_encode_audio_stream_created`. Once this stream state change is returned to Game Chat 2, the audio stream will become available for pre-encode audio manipulation.

When an existing `pre_encode_audio_stream` becomes unavailable to use for audio manipulation, the app will be notified through a `game_chat_stream_state_change` structure with it's `state_change_type` field set to `game_chat_stream_state_change_type::pre_encode_audio_stream_closed`. This is the app's opportunity to start cleaning up the resources associated with this audio stream. Once this stream state change is returned to Game Chat 2, the audio stream will become unavailable for pre-encode audio manipulation.

When a closed `pre_encode_audio_stream` has all of it's resources returned, the stream will be destroyed and the app will be notified through a `game_chat_stream_state_change` structure with it's `state_change_type` field set to `game_chat_stream_state_change_type::pre_encode_audio_stream_destroyed`. Any references or pointers to this stream should be cleaned up. Once this stream state change is returned to Game Chat 2, the audio stream memory will become invalid.

### Stream Users
The list of users associated with a stream can be inspected using `pre_encode_audio_stream::get_users()`.

### Audio Formats
The audio format of the buffers the app retrieves from Game Chat 2 can be inspected using `pre_encode_audio_stream::get_pre_processed_format()`. The pre-processed audio format will always be mono. The app should expect to handle data represented as 32-bit floats, 16-bit integers, and 32-bit integers.

The app must inform Game Chat 2 of the audio format of the manipulated buffers that are being submitted to it for encoding and transmission using `pre_encode_audio_stream::set_processed_format()`. Processed formats for pre-encode audio streams must meet these pre-conditions:

* The format must be mono.
* The format must be 32-bit float PCM, 32-bit integer PCM, or 16-bit integer PCM formats.
* The format's sample rate must follow pre-conditions based on it's platform. Xbox One ERA supports 8kHz, 12kHz, 16kHz, and 24kHz sample rates. UWP for Xbox One and PC supports 8kHz, 12kHz, 16kHz, 24kHz, 32kHz, 44.1kHz, and 48kHz sample rates.

### Retrieving and Submitting Audio
Apps can query pre-encode audio streams for the number of available buffers to process using `pre_encode_audio_stream::get_available_buffer_count()`. This information can be used if the app would like to delay audio processing until a minimum number of buffers are available. Only 10 buffers will be queued on each pre-encode audio stream and audio delays will introduce latency in the audio pipeline, so it's recommended that apps drain their pre-encode audio streams before they queue more than 4 buffers.

Apps can retrieve audio buffers from a pre-encode audio stream using `pre_encode_audio_stream::get_next_buffer()`. New audio buffers will be available on average, once every 40ms. Buffers returned by this method must be released to `pre_encode_audio_stream::return_buffer()` when they are done being used. A maximum of 10 queued or unreturned buffers can exist at any given time for a pre-encode audio stream. Once this limit is reached, new buffers captured from the player's audio source will be dropped until some of the outstanding buffers are returned.

Apps can submit their inspected and manipulated buffers back to Game Chat 2 for encoding and transmission using `pre_encode_audio_stream::submit_buffer()`. Game Chat 2 supports in-place and out-of-place audio manipulation, so the buffers submitted to `pre_encode_audio_stream::submit_buffer()` do not necessarily have to be the same buffers retrieved from `pre_encode_audio_stream::get_next_buffer()`. Privacy/privilege for these submitted buffers will be applied based on the users associated with this stream. Every 40ms, the next 40ms of audio from this stream will be encoded and transmitted. To prevent audio hiccups, buffers for audio that should be heard continuously should be submitted to this stream at a constant rate.

### Stream Contexts
Apps can manage custom pointer-sized context values on pre-encode audio streams using `pre_encode_audio_stream::set_custom_stream_context()` and `pre_encode_audio_stream::custom_stream_context()`. These custom stream contexts are helpful for creating mappings between Game Chat 2's audio streams and auxillary data: stream metadata, game state, etc.

### Example
Here's a simplified end-to-end sample for how to use pre-encode audio streams in one audio processing frame:

```cpp
uint32_t streamStateChangeCount;
game_chat_stream_state_change_array streamStateChanges;
chat_manager::singleton_instance().start_processing_stream_state_changes(&streamStateChangeCount, &streamStateChanges);

for (uint32_t streamStateChangeIndex = 0; streamStateChangeIndex < streamStateChangeCount; ++streamStateChangeIndex)
{
    switch (streamStateChanges[streamStateChangeIndex]->state_change_type)
    {
        case game_chat_stream_state_change_type::pre_encode_audio_stream_created:
        {
            pre_encode_audio_stream* stream = streamStateChanges[streamStateChangeIndex]->pre_encode_audio_stream;
            stream->set_processed_audio_format(...);
            stream->set_custom_stream_context(...);
            HandlePreEncodeAudioStreamCreated(stream);
            break;
        }

        case game_chat_2::game_chat_stream_state_change_type::pre_encode_audio_stream_closed:
        {
            HandlePreEncodeAudioStreamClosed(streamStateChanges[streamStateChangeIndex].pre_encode_audio_stream);
            break;
        }

        case game_chat_2::game_chat_stream_state_change_type::pre_encode_audio_stream_destroyed:
        {
            HandlePreEncodeAudioStreamDestroyed(streamStateChanges[streamStateChangeIndex].pre_encode_audio_stream);
            break;
        }

        ...
    }
}
chat_manager::singleton_instance().finish_processing_stream_state_changes(streamStateChanges);

uint32_t preEncodeAudioStreamCount;
pre_encode_audio_stream_array preEncodeAudioStreams;
chat_manager::singleton_instance().get_pre_encode_audio_streams(&preEncodeAudioStreamCount, &preEncodeAudioStreams);
for (uint32_t preEncodeAudioStreamIndex = 0; preEncodeAudioStreamIndex < preEncodeAudioStreamCount; ++preEncodeAudioStreamIndex)
{
    pre_encode_audio_stream* stream = preEncodeAudioStreams[preEncodeAudioStreamIndex];
    StreamContext* context = reinterpret_cast<StreamContext*>(stream->custom_stream_context());

    game_chat_audio_format audio_format = stream->get_pre_processed_format();

    uint32_t preProcessedBufferByteCount;
    void* preProcessedBuffer;
    stream->get_next_buffer(&preProcessedBufferByteCount, &preProcessedBuffer);

    while (preProcessedBuffer != nullptr)
    {
        void* processedBuffer = nullptr;
        switch (audio_format.bits_per_sample)
        {
            case 16:
            {
                assert (audio_format.sample_type == game_chat_sample_type::integer);
                processedBuffer = ManipulateChatBuffer<int16_t>(preProcessedBufferByteCount, preProcessedBuffer, context);
                break;
            }

            case 32:
            {
                switch (audio_format.sample_type)
                {
                    case game_chat_sample_type::integer:
                    {
                        processedBuffer = ManipulateChatBuffer<int32_t>(preProcessedBufferByteCount, preProcessedBuffer, context);
                        break;
                    }

                    case game_chat_sample_type::ieee_float:
                    {
                        processedBuffer = ManipulateChatBuffer<float>(preProcessedBufferByteCount, preProcessedBuffer, context);
                        break;
                    }

                    default:
                    {
                        assert(false);
                        break;
                    }
                }
                break;
            }

            default:
            {
                assert(false);
                break;
            }
        }
        // processedBuffer can be the same as preProcessedBuffer (in-place manipulation) or it can be a buffer of
        // memory not managed by Game Chat 2 (out-of-place manipulation).
        stream->submit_buffer(processedBuffer);
        // Only return buffers retrieved from Game Chat 2. Do not return foreign memory to return_buffer.
        stream->return_buffer(preProcessedBuffer);
        stream->get_next_buffer(&preProcessedBufferByteCount, &preProcessedBuffer);
    }
}

Sleep(audioProcessingPeriodInMilliseconds);
```

## Manipulating post-decode chat audio data

Game Chat 2 provides access to post-decode chat audio data through the `post_decode_audio_source_stream` and `post_decode_audio_sink_stream` classes, so that users may manipulate audio from remote users uniquely for each local receiver of chat audio.

### Sources and sinks
Unlike the pre-encode pipeline, the model for dealing with post-decode audio data is split across two classes: `post_decode_audio_source_stream` and `post_decode_audio_sink_stream`. Decoded audio from remote users can be retrieved from `post_decode_audio_source_stream` objects, manipulated, and sent to `post_decode_audio_sink_stream` objects for rendering. This allows for integration between Game Chat 2's post-decode audio processing pipeline and helpful audio middleware.

### Stream Lifetime
When a new `post_decode_audio_source_stream` or `post_decode_audio_sink_stream` instance is ready for the app to use, it will be delivered through a `game_chat_stream_state_change` structure with it's `state_change_type` field set to `game_chat_stream_state_change_type::post_decode_audio_source_stream_created` or `game_chat_stream_state_change_type::post_decode_audio_sink_stream_created`, respectively. Once this stream state change is returned to Game Chat 2, the audio stream will become available for post-decode audio manipulation.

When an existing `post_decode_audio_source_stream` or `post_decode_audio_sink_stream` becomes unavailable to use for audio manipulation, the app will be notified through a `game_chat_stream_state_change` structure with it's `state_change_type` field set to `game_chat_stream_state_change_type::post_decode_audio_source_stream_closed` or `game_chat_stream_state_change_type::post_decode_audio_sink_stream`, respectively. This is the app's opportunity to start cleaning up the resources associated with this audio stream. Once this stream state change is returned to Game Chat 2, the audio stream will become unavailable for post-decode audio manipulation. For source streams, this means that no more buffers will be queued for manipulation. For sink streams, this means that submitted buffers will no longer be rendered.

When a closed `post_decode_audio_source_stream` or `post_decode_audio_sink_stream` has all of it's resources returned, the stream will be destroyed and the app will be notified through a `game_chat_stream_state_change` structure with it's `state_change_type` field set to `game_chat_stream_state_change_type::post_decode_audio_source_stream_destroyed` or `game_chat_stream_state_change_type::post_decode_audio_sink_stream_destroyed`, respectively. Any references or pointers to this stream should be cleaned up. Once this stream state change is returned to Game Chat 2, the audio stream memory will become invalid.

### Stream Users
The list of remote users associated with a post-decode source stream can be inspected using `post_decode_audio_source_stream::get_users()`. The list of local users associated with a post-decode sink stream can be inspected using `post_decode_audio_sink_stream::get_users()`.

### Audio Formats
The audio format of the buffers the app retrieves from Game Chat 2 can be inspected using `post_decode_audio_source_stream::get_pre_processed_format()`. The pre-processed audio format will always be mono, 16-bit integer PCM.

The app must inform Game Chat 2 of the audio format of the manipulated buffers that are being submitted to it for rendering using `post_decode_audio_sink_stream::set_processed_format()`. Processed formats for post-decode audio sink streams must meet these pre-conditions:

* The format must have less than 64 channels.
* The format must be 16-bit integer PCM (optimal), 20-bit integer PCM (in a 24-bit container), 24-bit integer PCM, 32-bit integer PCM, or 32-bit float PCM (preferred format after 16-bit integer PCM). 
* The format's sample rate must be between 1000 and 200000 samples per second.

### Retrieving and Submitting Audio
Apps can query post-decode audio source streams for the number of available buffers to process using `post_decode_audio_source_stream::get_available_buffer_count()`. This information can be used if the app would like to delay audio processing until a minimum number of buffers are available. Only 10 buffers will be queued on each post-decode audio source stream and audio delays will introduce latency in the audio pipeline, so it's recommended that apps drain their post-decode audio streams before they queue more than 4 buffers.

Apps can retrieve audio buffers from a post-decode audio source stream using `post_decode_audio_source_stream::get_next_buffer()`. New audio buffers will be available on average, once every 40ms. Buffers returned by this method must be released to `post_decode_audio_source_stream::return_buffer()` when they are done being used. A maximum of 10 queued or unreturned buffers can exist at any given time for a post-decode audio source stream. Once this limit is reached, new decoded buffers from the remote player will be dropped until some of the outstanding buffers are returned.

Apps can submit their inspected and manipulated buffers back to Game Chat 2 through post-decode audio sink streams for rendering using `post_decode_audio_sink_stream::submit_mixed_buffer()`. Game Chat 2 supports in-place and out-of-place audio manipulation, so the buffers submitted to `post_decode_audio_sink_stream::submit_mixed_buffer()` do not necessarily have to be the same buffers retrieved from `post_decode_audio_source_stream::get_next_buffer()`. Every 40ms, the next 40ms of audio from this stream will be rendered. To prevent audio hiccups, buffers for audio that should be heard continuously should be submitted to this stream at a constant rate.

### Privacy and Mixing
Because of the post-decode pipeline's source-sink model, it is the app's responsibility to mix the buffers retrieved from `post_decode_audio_source_stream` objects and submit the mixed buffers to `post_decode_audio_sink_stream` objects for rendering. This also means that it is the app's responsibility to perform the mix with proper privacy and privilege enforced. Game Chat 2 provides `post_decode_audio_sink_stream::can_receive_audio_from_source_stream()` to make querying for this information simple and efficient.

### Chat indicators

Post-decode audio manipulation will not effect the chat indicator state for each user. For instance, when a remote user is muted, the audio will be provided to the app, but the chat indicator for that remote user will still indicate muted. When a remote user is talking, their audio will be provided, but the chat indicator will indicate talking regardless of whether the app provides an audio mix containing audio from that user. For more information on UI and the chat indicator, see [Using Game Chat 2](using-game-chat-2.md#ui). If extra app-specific restrictions are used to determine which users are present in an audio mix, it is the app's responsibility to consider those same restrictions when it is reading the chat indicators provided by Game Chat 2.

### Stream Contexts
Apps can manage custom pointer-sized context values on post-decode audio streams using the `set_custom_stream_context()` and `custom_stream_context()` methods. These custom stream contexts are helpful for creating mappings between Game Chat 2's audio streams and auxillary data: stream metadata, game state, etc.

### Example
Here's a simplified end-to-end sample for how to use post-decode audio streams in one audio processing frame:

```cpp
uint32_t streamStateChangeCount;
game_chat_stream_state_change_array streamStateChanges;
chat_manager::singleton_instance().start_processing_stream_state_changes(&streamStateChangeCount, &streamStateChanges);

for (uint32_t streamStateChangeIndex = 0; streamStateChangeIndex < streamStateChangeCount; ++streamStateChangeIndex)
{
    switch (streamStateChanges[streamStateChangeIndex]->state_change_type)
    {
        case game_chat_stream_state_change_type::post_decode_audio_source_stream_created:
        {
            post_decode_audio_source_stream* stream = streamStateChanges[streamStateChangeIndex]->post_decode_audio_source_stream;
            stream->set_custom_stream_context(...);
            HandlePostDecodeAudioSourceStreamCreated(stream);
            break;
        }

        case game_chat_stream_state_change_type::post_decode_audio_source_stream_closed:
        {
            HandlePostDecodeAudioSourceStreamClosed(stream);
            break;
        }

        case game_chat_stream_state_change_type::post_decode_audio_source_stream_destroyed:
        {
            HandlePostDecodeAudioSourceStreamDestroyed(stream);
            break;
        }

        case game_chat_stream_state_change_type::post_decode_audio_sink_stream_created:
        {
            post_decode_audio_sink_stream* stream = streamStateChanges[streamStateChangeIndex]->post_decode_audio_sink_stream;
            stream->set_custom_stream_context(...);
            stream->set_processed_format(...);
            HandlePostDecodeAudioSinkStreamCreated(stream);
            break;
        }

        case game_chat_stream_state_change_type::post_decode_audio_sink_stream_closed:
        {
            HandlePostDecodeAudioSinkStreamClosed(stream);
            break;
        }

        case game_chat_stream_state_change_type::post_decode_audio_sink_stream_destroyed:
        {
            HandlePostDecodeAudioSinkStreamDestroyed(stream);
            break;
        }

        ...
    }
}

chat_manager::singleton_instance().finish_processing_stream_state_changes(streamStateChanges);

uint32_t sourceStreamCount;
post_decode_audio_source_stream_array sourceStreams;
chatManager::singleton_instance().get_post_decode_audio_source_streams(&sourceStreamCount, &sourceStreams);

uint32_t sinkStreamCount;
post_decode_audio_sink_stream_array sinkStreams;
chatManager::singleton_instance().get_post_decode_audio_sink_streams(&sinkStreamCount, &sinkStreams);

//
// MixBuffer is a custom type defined as:
// struct MixBuffer
// {
//     uint32_t bufferByteCount;
//     void* buffer;
// };
//
std::vector<std::pair<post_decode_audio_source_stream*, MixBuffer>> cachedSourceBuffers;

for (uint32_t sourceStreamIndex = 0; sourceStreamIndex < sourceStreamCount; ++sourceStreamIndex)
{
    post_decode_audio_source_stream* sourceStream = sourceStreams[sourceStreamIndex];

    MixBuffer mixBuffer;
    sourceStream->get_next_buffer(&mixBuffer.bufferByteCount, &mixBuffer.buffer);
    if (buffer != nullptr)
    {
        // Stash the buffer to return after we are done with mixing. If this program was using audio middleware, now
        // would be an appropriate time to plumb the buffer through the middleware
        cachedSourceBuffer.push_back(std::pair<post_decode_audio_source_stream*, MixBuffer>{sourceStream, mixBuffer});
    }
}

// Loop over each sink stream, perform mixing, and submit
for (uint32_t sinkStreamIndex = 0; sinkStreamIndex < sinkStreamCount; ++sinkStreamIndex)
{
    post_decode_audio_sink_stream* sinkStream = sinkStreams[sinkStreamIndex];

    if (sinkStream->is_open())
    {
        std::vector<std::pair<MixBuffer, float>> buffersToMixForThisStream;

        for (const std::pair<post_decode_audio_source_stream, MixBuffer>& sourceBufferPair : cachedSourceBuffers)
        {
            float volume;
            if (sinkStream->can_receive_audio_from_source_stream(sourceBufferPair.first, &volume))
            {
                buffersToMixForThisStream.push_back(std::pair<MixBuffer, float>{sourceBufferPair.second, volume});
            }
        }

        if (buffersToMixForThisStream.size() > 0)
        {
            uint32_t mixedBufferByteCount;
            uint8_t* mixedBuffer;
            MixPostDecodeBuffers(buffersToMixForThisStream, &mixedBufferByteCount, &mixedBuffer);
            sinkStream->submit_mixed_buffer(mixedBufferByteCount, mixedBuffer);
        }
    }
}

// Return buffers after mix and submission
for (const std::pair<post_decode_audio_source_stream*, MixBuffer>& cachedSourceBuffer : cachedSourceBuffers)
{
    post_decode_audio_source_stream* sourceStream = cachedSourceBuffer.first;
    void* bufferToReturn = cachedSourceBuffer.second.buffer;
    sourceStream->return_buffer(bufferToReturn);
}

Sleep(audioProcessingPeriodInMilliseconds);
```

## Chat user lifetimes

Enabling real-time audio manipulation will affect the lifetimes of chat users. If `chat_manager::remove_user(chatUserX)` is called, the chat_user object pointed to by chatUserX will remain valid until all audio streams that reference chatUserX have been destroyed. Consider the following scenario:

```cpp
// At somepoint a chat user, chatUserX, leaves the game session.
chat_manager::singleton_instance().remove_user(chatUserX);

// chatUserX is still valid, but to avoid further synchronization, prevent non-audio-stream use of chatUserX
chatUserX = nullptr;

// On the audio processing thread...
uint32_t streamStateChangeCount;
game_chat_stream_state_change_array streamStateChanges;
chat_manager::singleton_instance().start_processing_stream_state_changes(&streamStateChangeCount, &streamStateChanges);
for (uint32_t streamStateChangeIndex = 0; streamStateChangeIndex < streamStateChangeCount; ++streamStateChangeIndex)
{
    switch (streamStateChanges[streamStateChangeIndex]->state_change_type)
    {
        ...

        // All of the streams associated with chatUserX will close.
        case Xs::game_chat_2::game_chat_stream_state_change_type::pre_encode_audio_stream_closed:
        {
            CleanupPreEncodeAudioStreamResources(streamStateChanges[streamStateChangeIndex].pre_encode_audio_stream);
            break;
        }

        ...
    }
}
chat_manager::singleton_instance().finish_processing_stream_state_changes(streamStateChanges);

// The next time the app processes stream state changes...
uint32_t streamStateChangeCount;
game_chat_stream_state_change_array streamStateChanges;
chat_manager::singleton_instance().start_processing_stream_state_changes(&streamStateChangeCount, &streamStateChanges);
for (uint32_t streamStateChangeIndex = 0; streamStateChangeIndex < streamStateChangeCount; ++streamStateChangeIndex)
{
    switch (streamStateChanges[streamStateChangeIndex]->state_change_type)
    {
        ...

        case Xs::game_chat_2::game_chat_stream_state_change_type::pre_encode_audio_stream_destroyed:
        {
            uint32_t chatUserCount;
            Xs::game_chat_2::chat_user_array chatUsers;
            streamStateChanges[streamStateChangeIndex].pre_encode_audio_stream->get_users(&chatUserCount, &chatUsers);
            assert(chatUserCount != 0);
            for (uint32_t chatUserIndex = 0; chatUserIndex < chatUserCount; ++chatUserIndex)
            {
                // chat_user objects such as chatUserX will still be valid while the destroyed state change is being processed.
                Log(chatUsers[chatUserIndex]->xbox_user_id());
            }
            break;
        }

        ...
    }
}
chat_manager::singleton_instance().finish_processing_stream_state_changes(streamStateChanges);
// Once the all destroyed state changes have been processed for all streams associated with chatUserX, it's memory will be invalidated.
// Do not call methods on chatUserX, e.g. chatUserX->xbox_user_id()
```
